{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "filenames = os.listdir(\"./CatsandDogs/dogs\")\n",
    "categories = []\n",
    "i = 0\n",
    "for filename in filenames: \n",
    "    src =\"./CatsandDogs/dogs/\" + filename\n",
    "    dst = \"./CatsandDogs/dogs/\"+\"dog\"+filename \n",
    "    os.rename( src,dst) \n",
    "    i += 1\n",
    "#('All the image file of dogs 0,1,2.. etc is updated to dog0,dog1 etc')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(\"./CatsandDogs/cats\")\n",
    "categories = []\n",
    "i = 0\n",
    "for filename in filenames: \n",
    "    src =\"./CatsandDogs/cats/\" + filename\n",
    "    dst = \"./CatsandDogs/cats/\"+\"cat\"+filename \n",
    "    os.rename( src,dst) \n",
    "    i += 1\n",
    "    \n",
    "#('All the image file of dogs 0,1,2.. etc is updated to cat0,cat1 etc')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "#'Copying all images to one directory';\n",
    "for filename in os.listdir(\"./CatsandDogs/cats\"):\n",
    "    src=\"./CatsandDogs/cats/\" + filename\n",
    "    dst=\"./CatsandDogs/dogs/\"\n",
    "    shutil.copy(src, dst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../input/generatedogdata/dogs/dogs\"\n",
    "new_path_train=\"./CatsandDogs/test\"\n",
    "\n",
    "counter=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  image data retreived\n",
      "2000  image data retreived\n",
      "3000  image data retreived\n",
      "4000  image data retreived\n",
      "5000  image data retreived\n",
      "6000  image data retreived\n",
      "7000  image data retreived\n",
      "8000  image data retreived\n",
      "9000  image data retreived\n",
      "10000  image data retreived\n",
      "11000  image data retreived\n",
      "12000  image data retreived\n",
      "13000  image data retreived\n",
      "14000  image data retreived\n",
      "15000  image data retreived\n",
      "16000  image data retreived\n",
      "17000  image data retreived\n",
      "18000  image data retreived\n",
      "19000  image data retreived\n",
      "20000  image data retreived\n",
      "21000  image data retreived\n",
      "22000  image data retreived\n",
      "23000  image data retreived\n",
      "24000  image data retreived\n",
      "25000  image data retreived\n"
     ]
    }
   ],
   "source": [
    "test=[]\n",
    "test_label=[]\n",
    "label=[]\n",
    "data1=[]\n",
    "counter=1\n",
    "check=0;\n",
    "for file in os.listdir(path):\n",
    "    image_data=cv2.imread(os.path.join(path,file), cv2.IMREAD_GRAYSCALE)\n",
    "    image_data=cv2.resize(image_data,(64,64))\n",
    "    \n",
    "    if file.startswith(\"cat\"):\n",
    "        label.append(0)\n",
    "        check=0\n",
    "        \n",
    "    elif file.startswith(\"dog\"):\n",
    "          label.append(1);check=1\n",
    "    if counter<2000:\n",
    "        test.append(image_data/255)\n",
    "        test_label.append(check)\n",
    "    try:\n",
    "        data1.append(image_data/255)\n",
    "    except:\n",
    "        label=label[:len(label)-1]\n",
    "        print('erro')\n",
    "    counter+=1\n",
    "    if counter%1000==0:\n",
    "        print (counter,\" image data retreived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 62, 62, 3)         30        \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 62, 62, 10)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 30, 30, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 30, 30, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 30, 30, 10)        2510      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 7, 7, 10)          410       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 490)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 490)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               49100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 53,341\n",
      "Trainable params: 53,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "im_width=64\n",
    "im_height=64\n",
    "model=Sequential()\n",
    "model.add(Conv2D(kernel_size=(3,3),filters=3,input_shape=(im_width,im_height,1),activation=\"relu\",padding=\"valid\"))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(kernel_size=(3,3),filters=10,activation=\"relu\",padding=\"same\"))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Conv2D(kernel_size=(3,3),filters=10,activation=\"relu\",padding=\"same\"))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(kernel_size=(5,5),filters=10,activation=\"relu\",padding=\"same\"))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Conv2D(kernel_size=(2,2),strides=(2,2),filters=10))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(100,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 64, 64)\n",
      "(1999,)\n",
      "(1999, 64, 64, 1)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data1=np.array(data1)\n",
    "print (data1.shape)\n",
    "data1=data1.reshape((data1.shape)[0],(data1.shape)[1],(data1.shape)[2],1)\n",
    "test=np.array(test)\n",
    "test_label=np.array(test_label)\n",
    "test=test.reshape((test.shape)[0],(test.shape)[1],(test.shape)[2],1)\n",
    "labels=np.array(label)\n",
    "print(test_label.shape)\n",
    "print(test.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 1999 samples\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.5079 - acc: 0.7480 - val_loss: 0.4863 - val_acc: 0.7664\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.5005 - acc: 0.7558 - val_loss: 0.4640 - val_acc: 0.7689\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.4946 - acc: 0.7586 - val_loss: 0.4582 - val_acc: 0.7754\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.4882 - acc: 0.7642 - val_loss: 0.4519 - val_acc: 0.7844\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.4832 - acc: 0.7650 - val_loss: 0.4516 - val_acc: 0.7739\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.4771 - acc: 0.7676 - val_loss: 0.4830 - val_acc: 0.7704\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.4726 - acc: 0.7733 - val_loss: 0.4464 - val_acc: 0.7794\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.4657 - acc: 0.7778 - val_loss: 0.5210 - val_acc: 0.7399\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.4613 - acc: 0.7793 - val_loss: 0.4301 - val_acc: 0.7959\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 0.4576 - acc: 0.7824 - val_loss: 0.4286 - val_acc: 0.7909\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.4514 - acc: 0.7840 - val_loss: 0.4365 - val_acc: 0.7899\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.4475 - acc: 0.7859 - val_loss: 0.4187 - val_acc: 0.8034\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.4443 - acc: 0.7904 - val_loss: 0.4159 - val_acc: 0.7999\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 0.4395 - acc: 0.7906 - val_loss: 0.4141 - val_acc: 0.8069\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.4361 - acc: 0.7934 - val_loss: 0.4317 - val_acc: 0.7869\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.4331 - acc: 0.7961 - val_loss: 0.4077 - val_acc: 0.8079\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.4305 - acc: 0.7991 - val_loss: 0.4055 - val_acc: 0.8049\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.4275 - acc: 0.8009 - val_loss: 0.4111 - val_acc: 0.8084\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.4245 - acc: 0.8012 - val_loss: 0.4117 - val_acc: 0.8069\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.4228 - acc: 0.7983 - val_loss: 0.4383 - val_acc: 0.7934\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.4198 - acc: 0.8021 - val_loss: 0.4055 - val_acc: 0.8199\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.4162 - acc: 0.8066 - val_loss: 0.4422 - val_acc: 0.7989\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.4145 - acc: 0.8056 - val_loss: 0.3898 - val_acc: 0.8194\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.4134 - acc: 0.8076 - val_loss: 0.3789 - val_acc: 0.8229\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.4103 - acc: 0.8086 - val_loss: 0.3823 - val_acc: 0.8259\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.4071 - acc: 0.8133 - val_loss: 0.4069 - val_acc: 0.8129\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 0.4043 - acc: 0.8124 - val_loss: 0.3993 - val_acc: 0.8154\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.4038 - acc: 0.8130 - val_loss: 0.3856 - val_acc: 0.8239\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.4036 - acc: 0.8134 - val_loss: 0.3706 - val_acc: 0.8229\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.3982 - acc: 0.8162 - val_loss: 0.3804 - val_acc: 0.8224\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.3949 - acc: 0.8151 - val_loss: 0.3563 - val_acc: 0.8404\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.3955 - acc: 0.8174 - val_loss: 0.3635 - val_acc: 0.8319\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.3896 - acc: 0.8192 - val_loss: 0.3913 - val_acc: 0.8234\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.3895 - acc: 0.8194 - val_loss: 0.3827 - val_acc: 0.8244\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.3885 - acc: 0.8215 - val_loss: 0.3569 - val_acc: 0.8349\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.3845 - acc: 0.8202 - val_loss: 0.3816 - val_acc: 0.8294\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.3852 - acc: 0.8211 - val_loss: 0.3548 - val_acc: 0.8459\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.3837 - acc: 0.8242 - val_loss: 0.3786 - val_acc: 0.8259\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.3782 - acc: 0.8254 - val_loss: 0.3416 - val_acc: 0.8474\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.3763 - acc: 0.8258 - val_loss: 0.3866 - val_acc: 0.8164\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 0.3741 - acc: 0.8299 - val_loss: 0.3499 - val_acc: 0.8384\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.3750 - acc: 0.8284 - val_loss: 0.3461 - val_acc: 0.8409\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.3724 - acc: 0.8288 - val_loss: 0.3387 - val_acc: 0.8424\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.3676 - acc: 0.8325 - val_loss: 0.3449 - val_acc: 0.8504\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 3s 105us/step - loss: 0.3676 - acc: 0.8313 - val_loss: 0.3373 - val_acc: 0.8499\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.3660 - acc: 0.8349 - val_loss: 0.3250 - val_acc: 0.8574\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 3s 105us/step - loss: 0.3659 - acc: 0.8348 - val_loss: 0.3321 - val_acc: 0.8599\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 3s 105us/step - loss: 0.3625 - acc: 0.8346 - val_loss: 0.3245 - val_acc: 0.8554\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.3558 - acc: 0.8399 - val_loss: 0.3200 - val_acc: 0.8574\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.3569 - acc: 0.8396 - val_loss: 0.3154 - val_acc: 0.8614\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.3557 - acc: 0.8388 - val_loss: 0.3091 - val_acc: 0.8699\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.3534 - acc: 0.8385 - val_loss: 0.3316 - val_acc: 0.8489\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.3534 - acc: 0.8412 - val_loss: 0.3097 - val_acc: 0.8694\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.3476 - acc: 0.8436 - val_loss: 0.3060 - val_acc: 0.8699\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.3468 - acc: 0.8451 - val_loss: 0.3085 - val_acc: 0.8644\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 3s 105us/step - loss: 0.3480 - acc: 0.8448 - val_loss: 0.3065 - val_acc: 0.8704\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.3422 - acc: 0.8466 - val_loss: 0.3100 - val_acc: 0.8704\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.3407 - acc: 0.8475 - val_loss: 0.3039 - val_acc: 0.8724\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.3378 - acc: 0.8474 - val_loss: 0.2984 - val_acc: 0.8704\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.3355 - acc: 0.8463 - val_loss: 0.3068 - val_acc: 0.8719\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.3327 - acc: 0.8500 - val_loss: 0.2977 - val_acc: 0.8749\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.3301 - acc: 0.8516 - val_loss: 0.3101 - val_acc: 0.8619\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.3270 - acc: 0.8548 - val_loss: 0.3185 - val_acc: 0.8609\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.3270 - acc: 0.8532 - val_loss: 0.2727 - val_acc: 0.8844\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 0.3218 - acc: 0.8554 - val_loss: 0.2823 - val_acc: 0.8889\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.3173 - acc: 0.8598 - val_loss: 0.2960 - val_acc: 0.8679\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 0.3188 - acc: 0.8574 - val_loss: 0.2733 - val_acc: 0.8884\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.3131 - acc: 0.8625 - val_loss: 0.2916 - val_acc: 0.8774\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.3093 - acc: 0.8627 - val_loss: 0.2702 - val_acc: 0.8819\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.3083 - acc: 0.8625 - val_loss: 0.2879 - val_acc: 0.8719\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.3041 - acc: 0.8653 - val_loss: 0.2525 - val_acc: 0.8959\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.3003 - acc: 0.8673 - val_loss: 0.2626 - val_acc: 0.8889\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 3s 105us/step - loss: 0.2981 - acc: 0.8678 - val_loss: 0.2394 - val_acc: 0.9055\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.2938 - acc: 0.8727 - val_loss: 0.2926 - val_acc: 0.8714\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.2900 - acc: 0.8736 - val_loss: 0.2412 - val_acc: 0.8954\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.2832 - acc: 0.8771 - val_loss: 0.2293 - val_acc: 0.9090\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 0.2801 - acc: 0.8803 - val_loss: 0.2950 - val_acc: 0.8774\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 0.2789 - acc: 0.8778 - val_loss: 0.2687 - val_acc: 0.8754\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.2724 - acc: 0.8802 - val_loss: 0.2381 - val_acc: 0.9015\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 0.2694 - acc: 0.8858 - val_loss: 0.2205 - val_acc: 0.9105\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.2669 - acc: 0.8831 - val_loss: 0.2469 - val_acc: 0.8984\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.2638 - acc: 0.8870 - val_loss: 0.1983 - val_acc: 0.9315\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.2573 - acc: 0.8906 - val_loss: 0.2121 - val_acc: 0.9185\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.2566 - acc: 0.8913 - val_loss: 0.2024 - val_acc: 0.9175\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.2486 - acc: 0.8939 - val_loss: 0.1804 - val_acc: 0.9395\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.2455 - acc: 0.8966 - val_loss: 0.1756 - val_acc: 0.9400\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.2439 - acc: 0.8967 - val_loss: 0.1673 - val_acc: 0.9385\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.2401 - acc: 0.8983 - val_loss: 0.1617 - val_acc: 0.9510\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.2375 - acc: 0.9004 - val_loss: 0.1630 - val_acc: 0.9490\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.2294 - acc: 0.9057 - val_loss: 0.1611 - val_acc: 0.9460\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.2270 - acc: 0.9054 - val_loss: 0.1421 - val_acc: 0.9560\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.2233 - acc: 0.9079 - val_loss: 0.1550 - val_acc: 0.9460\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.2224 - acc: 0.9074 - val_loss: 0.1394 - val_acc: 0.9565\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 0.2177 - acc: 0.9101 - val_loss: 0.1580 - val_acc: 0.9435\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.2135 - acc: 0.9112 - val_loss: 0.1458 - val_acc: 0.9545\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.2124 - acc: 0.9113 - val_loss: 0.1418 - val_acc: 0.9495\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.2105 - acc: 0.9141 - val_loss: 0.1221 - val_acc: 0.9645\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.2033 - acc: 0.9146 - val_loss: 0.1186 - val_acc: 0.9630\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.2006 - acc: 0.9173 - val_loss: 0.1218 - val_acc: 0.9650\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 0.1971 - acc: 0.9174 - val_loss: 0.1178 - val_acc: 0.9650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6fb7e719b0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(data1, labels,\n",
    "          batch_size=100,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "           validation_data=(test, test_label))\n",
    "\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 11.778953300230857\n",
      "Test accuracy: 96.498249127544\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test, test_label, verbose=0)\n",
    "print('Test loss:', score[0]*100)\n",
    "print('Test accuracy:', score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
